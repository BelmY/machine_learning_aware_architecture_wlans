
%% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}


\usepackage{url}


% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\usepackage{graphicx}
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage{amsfonts}
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.


\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{soul}

% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{A Flexible Machine Learning-Aware Architecture\\ for Future WLANs}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Francesc~Wilhelmi,~Sergio~Barrachina-Mu\~noz,~Boris~Bellalta,~Cristina~Cano,~Anders~Jonsson,~and~Vishnu~Ram% <-this % stops a space
\thanks{Francesc Wilhelmi, Sergio Barrachina-Mu\~noz, Boris Bellalta, and Anders Jonsson are with Universitat Pompeu Fabra (UPF); Cristina Cano is with Universitat Oberta de Catalunya (UOC); Vishnu Ram is currently working as an independent researcher.}% <-this % stops a space
}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2015 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Lots of hopes have been placed \textcolor{orange}{on} \textcolor{blue}{machine learning (ML)} as a key enabler of future wireless networks. By taking advantage of the large volumes of data generated by networks, ML is expected to deal with the ever-increasing complexity of networking problems. Unfortunately, current \textcolor{orange}{networks} are not yet prepared \textcolor{orange}{to support} the ensuing requirements of ML-based applications \textcolor{orange}{in terms of} data collection, processing, and output distribution. This article points out the architectural requirements that are needed to pervasively include ML as part of future wireless networks operation. \textcolor{orange}{Specifically, we look into \textcolor{blue}{wireless local area networks (WLANs)}, which, due to their nature, can be found in multiple forms, ranging from cloud-based to edge-computing-like deployments. In particular,} we propose to adopt the International Telecommunications Union (ITU) unified architecture for 5G and beyond. Based on the ITU's architecture, we provide insights on the main requirements and the major challenges of introducing ML to the multiple modalities of WLANs. \textcolor{blue}{Finally, we showcase the superiority of the architecture through an ML-enabled use case for future networks.}  %\textcolor{blue}{Finally, numerical results show the superiority of ML-based methods enabled by the architecture in front of currently adopted approaches.}
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
\textcolor{blue}{Architecture, Future Networks, ITU, Machine Learning, Wireless Local Area Networks}
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\begin{table*}[t!]
	\caption{Machine learning methods, algorithms, potential networking applications, and examples of input data.}
	\label{table:ml_taxonomy}
	\centering
	\begin{tabular}{|p{.09\textwidth}|p{.28\textwidth}|p{.25\textwidth}|p{.25\textwidth}|}
		\hline
		\textbf{ML method} & \textbf{Algorithms} & \textbf{Potential applications} & \textbf{Examples of input data} \\\hline
		Supervised learning & Linear classifiers, regression methods (e.g., \textcolor{blue}{autoregressive integrated moving average}), neural networks, hidden Markov models, random forest, support vector machines, k-nearest neighbors, principal component analysis &Traffic forecasting, mobility pattern prediction, flow classification, routing, anomaly detection, spectrum management, failure detection, QoE prediction & IP traffic matrices, temporal user location, availability of routing paths, application data, channel measurements, performance metrics \\\hline
		Unsupervised learning & Clustering, mixture models, generative models, non-negative matrix factorization, evolutionary algorithms & traffic classification, virtual topology design, path computation, intruder detection, signal separation& IP traffic matrices, historical end-to-end bit-rate, received symbols \\\hline
		Reinforcement learning & Monte Carlo, Q-learning, \textcolor{blue}{state-action-reward-state-action (SARSA)}, deep Q network, actor-critic, multi-armed bandits, learning automaton, \textcolor{blue}{Markov decision processes} & Power control, rate adaptation, routing, channel selection, spatial reuse, smart caching, traffic offloading, cognitive channel access, energy harvesting, \textcolor{blue}{energy efficiency} & Channel measurements, link status, performance metrics (e.g., throughput, delay), \textcolor{blue}{server occupation, power consumption} \\\hline
	\end{tabular}
\end{table*}

\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
Wireless communications have reached a point where a paradigm shift is required for satisfying the increasing needs of next-generation applications \cite{osseiran2014scenarios}. Based on the current trend, \textcolor{blue}{artificial intelligence (AI)}, and more precisely \textcolor{blue}{machine learning (ML)}, are expected to conduct a revolution, especially regarding the network planning, operation, and management of the 5th and 6th generation (5G/6G) of mobile communications. 

ML is meant to empower a computational system for learning automatically, based on experience, so that future situations can be properly managed without having been programmed explicitly. Concerning wireless communications, there is a huge amount of unexploited data generated at both infrastructure and user levels, which could be extremely useful for learning complex patterns\textcolor{orange}{, which may allow improving network performance}. For instance, the behavior of users in a given network-oriented service can be predicted through ML, based on the information from previous sessions. \textcolor{orange}{Based on these predictions, network resources can be properly accommodated} in future sessions, thus leading to an optimized solution.

Unfortunately, the potential benefits of ML for real networks are currently limited by the existing infrastructure, which is not yet prepared to accommodate ML-oriented tasks such as data collection, processing, and output distribution. Instead, current networking systems are typically meant for delivering content, without taking into account the underlying characteristics of the processes that generate it. 

The first steps towards AI-enabled networking are currently being made in 5G through network function virtualization (NFV). Unlike traditional hardware-based networks, NFV allows rapid elasticity and fast reconfiguration on assigning network resources, which is particularly useful to enable verticals such as autonomous driving in the automotive sector or smart manufacturing in \textcolor{blue}{industry 4.0}. Besides, network virtualization is useful to boost inter-operator coordination, which would bring the ML operation to a macro-scale level, thus counting with vast information and computation resources. 

To conduct the evolution towards ML-aware networks, standardization is key to reach consensus between operators and manufacturers. In this regard, we find many initiatives held by standardization organizations, from which we highlight the Focus Group on Machine Learning for Future Networks including 5G (FG-ML5G), which belongs to the International Telecommunication Union Telecommunication Standardization Sector (ITU-T). The FG-ML5G aims to enable the convergence of future communications with ML technologies. To that end, the focus group has released a specification on a \emph{Unified architecture for 5G and beyond}, which has recently been turned into an ITU Recommendation \cite{itu2019architecture}. The ITU's standardized architecture provides a common nomenclature for ML-related mechanisms so that interoperability with other networking systems is achieved. 

Apart from the ITU-T initiatives, other important standardization bodies such as the 3rd Generation Partnership Project (3GPP) or the European Telecommunications Standards Institute (ETSI) are currently working on the integration of data analytics to network functions. The 3GPP contemplates AI as one of the priority topics for shaping its upcoming release (Release 17), and architectural requirements are currently under study \cite{3gpp2019study}. Furthermore, we highlight the ETSI groups on Experiential Networked Intelligence (ENI) and Zero-touch network and Service Management (ZSM), which actively study the integration of AI to networks \cite{etsi2019architecture}. Unlike the ITU's unified architecture, most of the work held by the 3GPP and the ETSI focuses on centralized data collection and data analytics solutions. Nevertheless, we understand that the works in \cite{itu2019architecture, 3gpp2019study, etsi2019architecture} are complementary to each other.
% Alternative architecture: \cite{nekovee2019mobile}

To contribute to the evolution of wireless communications towards AI-based systems, we provide a realization of an ML-aware architecture for IEEE 802.11 \textcolor{blue}{wireless local area networks (WLANs)}, which will be an essential part of the 5G/6G ecosystem in the unlicensed bands. Unlike for cellular networks, WLANs have received much less attention when designing AI-aware architectural solutions. The fact is that cellular-based deployments fit in perfectly with big data analytics, due to the vast amount of data and high computation resources available for mobile network operators (MNOs). In contrast, WLANs pose a set of specific challenges resulting from their multiple deployment modes (e.g., campus network, residential usage) and their typical decentralized nature. Despite WLANs can count with plenty of data to be used by ML methods in large and planned deployments, we find other  \textcolor{orange}{residential-type} scenarios that lack \textcolor{orange}{of} powerful centralized equipment. In  \textcolor{orange}{these} cases, huge computing and processing  \textcolor{orange}{resources} cannot be endowed to the ML operation.

In particular, we adopt the module-based ITU's architecture, which is flexible in terms of deployment heterogeneity and provides adaptability to the problem instance and the set of available resources. This is an important requirement for the integration of different ML-based approaches into the different modalities of WLANs. For instance, despite deep learning is a powerful solution, it entails a set of computation, storage and communication requirements that may not be fulfilled in certain deployments or parts of the network.

% ----------------------------------
% -
% 	-- Introduction to ML --
% -
% ----------------------------------
\section{Machine Learning as Enabler of Future Wireless Networks} 
\label{section:intro_ML}
In this section, we discuss the role of ML for sustaining the progress of future wireless networks. Then, we motivate the application of ML to IEEE 802.11 WLANs through a set of illustrative ML-driven use cases.

\subsection{Machine Learning in Communications}
% 5G and ML as enabler
The proliferation of new communication-based applications is defining the shape of future networks through a set of strict requirements \cite{itu2019use}. Some examples are \textcolor{blue}{vehicle to everything (V2X)}, \textcolor{blue}{industry 4.0}, and \textcolor{blue}{virtual reality / augmented reality (VR/AR)}.  \textcolor{orange}{These} applications are really challenging in terms of bandwidth, latency, reliability, and scalability. In this regard, next-generation wireless networks  \textcolor{orange}{are expected to}:
\begin{enumerate}
	\item Provide a very high data rate (10-20 Gbps).
	\item Support a massive amount of connected devices (1,000,000 devices/km$^2$).
	\item Dramatically reduce the latency ($<5$ ms) whilst maintaining a low packet error rate (1 packet lost for every 10$^5$ packets sent).
\end{enumerate}

In 5G, the previous concepts are referred to as enhanced mobile broadband (eMBB), massive machine to machine and \textcolor{blue}{Internet of things (IoT)} communication (mMTC), and ultra-reliable and low latency communication (uRLLC), respectively. Similarly, IEEE 802.11 groups are also considering those aspects in the design of next-generation amendments, such as high efficiency (HE) IEEE 802.11ax and extreme high throughput (EHT) IEEE 802.11be.

% Overview ML with formal definitions
To meet the abovementioned strict requirements, not only a technological innovation is expected (e.g., use of more spectrum or improve multiple-antennas technologies), but a paradigm shift is necessary when designing solutions for network planning, operation, and management. In particular, intelligent wireless networks need to be empowered with cognitive and context-aware capabilities, which may require additional infrastructure such as environmental sensors and cameras. To that end, ML is expected to be important during the lifetime of 5G and will become pervasive - as included from the beginning in their conception - in 6G networks. 

The actual utility of ML lies in those problems that are hard to solve by hand-programming due to their underlying complex patterns (e.g., network traffic prediction). Formally, a machine is said to learn if it improves the performance $\mathbb{P}$ obtained from undertaking task $\mathbb{T}$, based on the gathered experience $\mathbb{E}$ \cite{mitchell1997machine}. Different ML techniques have been categorized in multiple ways, but the most common taxonomy differentiates between supervised learning (labeled data is used for training), unsupervised learning (no labels are used on input data), and reinforcement learning (exploration-exploitation trade-off with label/unlabeled data). Table \ref{table:ml_taxonomy} provides a list of algorithms and potential networking applications for each type of ML \textcolor{blue}{techniques}, as well as some examples of input data  \textcolor{orange}{to be used by these} methods. For further details, we address the interested reader to \cite{jiang2016machine, zhang2019deep, usama2019unsupervised}, which survey a plethora of ML-based applications for networking.

% 1 - Architectural proposals	
Apart from the specific ML solutions to problems in communications, some efforts have been made towards enabling AI-aware networking in more general terms. In this regard, several architectural proposals have been provided so far \cite{bi2015wireless,chih2017big,wang2018machine}. Most of the referenced works agree in the necessary steps for enabling big data analytics in cellular deployments: (1) data collection, (2) data preparation, (3) data analysis, and (4) decision making. Nevertheless, none of these works provide architectural guidelines to introduce ML to wireless networks. In contrast, the ITU's architecture looks deeper into the ML operation and targets the actual procedures involving information gathering, processing, and communication. In addition to the architectural guidelines, the ITU-T has provided a data handling framework for ML-aware networks \cite{itu2019data}, which defines processes concerning data collection, processing, and output distribution. 

\subsection{Machine Learning-Enabled Use Cases in WLANs}
To showcase the potential of applying AI in IEEE 802.11 WLANs, we next describe a set of use cases where ML allows improving the network operation and performance.

\subsubsection{OFDMA-Based Smart Network Slicing} 
Network slicing is one of the hottest topics in 5G because it allows separating network resources virtually to meet diverse application requirements. In next-generation WLANs, network slicing can be realized through the allocation of radio resources via orthogonal frequency-division multiple access (OFDMA). However, the heterogeneity of applications running in multiple devices and their subsequent elasticity prevent \textcolor{orange}{allocating} frequency resources easily. \textcolor{orange}{To solve this, ML can be used to make} predictions on the user requirements so that the access network can be optimized.

As an example, Fig. \ref{fig:use_cases} shows a scenario where multiple users \textcolor{orange}{operate under} different requirements, based on the applications they use. While the central controller can make predictions on user behavior, the local schedulers can consider information such as the user profile, the current performance, and the environmental circumstances. In this regard, the \textcolor{blue}{access point (AP)} can allocate the most suitable OFDMA resources to each device, \textcolor{orange}{based on the} predicted needs and \textcolor{orange}{network} status.

\begin{figure}[ht!]
	\centering
	%\hspace{5mm}
	\includegraphics[width=1\columnwidth]{network_slicing_ofdma}
	%\subfigure[Network slicing]{\includegraphics[width=1\columnwidth]{network_slicing_ofdma}\label{fig:network_slicing_ofdma}}
	%	\subfigure[Access Point association]{\includegraphics[width=1\columnwidth]{use_case_ap_association}\label{fig:use_case_ap_association}}
	\caption{OFDMA-based smart network slicing.}
	\label{fig:use_cases}
\end{figure}

\subsubsection{Cloud-Based User Association and Handover}
Most of the current user association and handover procedures held in WLANs typically rely on the strongest signal first (SSF) mechanism. This might be problematic in terms of load balancing \textcolor{orange}{and can potentially lead} to severe performance degradation \textcolor{orange}{in} saturated \textcolor{blue}{basic service sets (BSSs)}. By introducing ML, it is possible to handle contextual information such as the traffic load, which can \textcolor{orange}{be useful for} decision-making. Furthermore, mobility pattern prediction and predicted user requirements can be included in the system, thus empowering the association and handover mechanisms with insightful information. %\textcolor{orange}{Predictions can be provided, for instance, by Deep Neural Networks (DNN).}

%The ML-enabled user association solution is illustrated in Fig. \ref{fig:use_case_ap_association}. A cloud-oriented service obtains data from the different connected WLANs (e.g., number of associated devices, traffic load, performance reports, etc.), which are used for training. Then, new requests are addressed by the ML mechanism, which chooses the best predicted AP for the (re)association, based on the corresponding optimization goals.

\subsubsection{Inference-Based Coordinated Scheduling}
Contrary to traditional cellular-type networks, WLAN deployments can be chaotic, especially in residential scenarios where anyone can set-up an AP and create a wireless network. This typically leads to complex scenarios \textcolor{orange}{where inter-BSS interactions prevent the existing scheduling approaches to ensuring quality of service.} \textcolor{orange}{Fortunately}, ML can be used to infer these interactions and provide a solution accordingly. In particular, through coordinated ML-assisted scheduling, different APs can trigger uplink/downlink transmissions from/to the appropriate stations (STAs), thus increasing the network throughput \textcolor{orange}{whilst} reducing the number of packet collisions.

\subsubsection{Reinforcement Learning-Based Spatial Reuse} 
Spatial reuse aims to improve channel utilization through sensitivity adjustment mechanisms. However, selecting the best sensitivity threshold is not trivial, given the complex spatial interactions that occur among WLANs and the high action space. \textcolor{orange}{To that} purpose, reinforcement learning can be introduced to improve spectral efficiency in a decentralized manner so that each WLAN learns based on experience.

% ----------------------------------
% -
% 	-- ITU-T ARCHITECTURE --
% -
% ----------------------------------

\section{ITU Unified Architecure for Future Networks}
\label{section:itu_architecture}

\begin{figure*}[!ht]
	\centering
	\includegraphics[width=0.5\textwidth]{itu_ml_architecture}
	\caption{ITU logical architecture for future networks \cite{itu2019architecture}. \textcolor{blue}{Entities contain input/output interfaces for communication, while the ML intent is a declarative file with information related to the use case.}}
	\label{fig:itu_ml_architecture}
\end{figure*}

The FG-ML5G was created in November 2017 by its parent group, the ITU-T Study Group 13, \textcolor{orange}{to study} the integration of ML mechanisms into future networks. This includes the definition of interfaces, protocols, data formats, and architectures. During its lifetime, the FG-ML5G has released several reports and contributions. Among them, we highlight the ITU's logical interoperable architecture for future networks \cite{itu2019architecture}, which defines an ML overlay that operates on the top of any unspecified underlay network technology (e.g., 3GPP, EdgeX, IEEE 802.11). The ITU's architecture aims to fulfill a set of technology-agnostic high-level requirements by the utilization of ML. For instance, the architecture must be able to support multiple types of data, thus taking advantage of heterogeneous data sources. 

Figure \ref{fig:itu_ml_architecture} shows the elements that compose the ML overlay (management subsystem, multi-level ML pipeline, and closed-loop subsystem), which are further described in the following subsections. Based on this \textcolor{orange}{standard} overlay, ML applications can be instantiated in the logical entities (represented by white boxes).

\subsection{Management Subsystem} 
The management subsystem is in charge of the deployment and the orchestration of the ML services \textcolor{orange}{that operate} in the underlying network. To that purpose, the \textcolor{blue}{machine learning function orchestrator (MLFO)} entity is defined. \textcolor{blue}{The MLFO is first instantiated by a declarative intent that uses a meta language, which specifies the ML use case to be applied, including initialization, policies, and constraints. Then, the MLFO initializes the elements of the multi-level ML pipeline in the corresponding devices and monitors their operation during execution.}

\subsection{Multi-Level Machine Learning Pipeline} 
The multi-level ML pipeline is formed by a set of logical entities that perform the actual ML activity in a given network underlay. The ML pipeline is instantiated and managed by the management subsystem and it is mainly in charge of the data collection and pre-processing, ML model application, and output distribution. The logical entities that compose the ML pipeline are as follows:
\begin{itemize}
	\item \textbf{Source (src):} \textcolor{orange}{generates data to be used by the ML mechanism.}
	\item \textbf{Collector (C):} \textcolor{orange}{collects the data generated by sources.}
	\item \textbf{Pre-processor (PP):} \textcolor{orange}{prepares the data collected for its utilization by the ML mechanism.}
	\item \textbf{Model (M):} \textcolor{orange}{applies an ML model according to the use case.}
	\item \textbf{Policy (P):} \textcolor{orange}{provides a set of constraints and/or guidelines that delimit the behavior of the model.}
	\item \textbf{Distributor (D):} \textcolor{orange}{spreads the ML output across all the corresponding targets (or sinks).}
	\item \textbf{Sink (sink):} \textcolor{orange}{applies the ML output that is received from the distributor.}
\end{itemize}

\subsection{Closed-loop Subsystem} 
In order to address network dynamics, the ML operation is assisted by a closed-loop subsystem. In particular, a sandbox environment can be used to reproduce (internal network) or simulate (simulator/emulator) the effect of certain ML optimization, so that additional information is provided to the system beforehand. As for the ML pipeline, the closed-loop subsystem is orchestrated by the management subsystem. Network simulators (e.g., ns-3, Komondor \cite{barrachina2019komondor}) are examples of closed-loop subsystems, which can serve two purposes: \emph{i)} generate synthetic data to be used for training, and \emph{ii)} \textcolor{blue}{run simulations} for devising the potential of a given ML method to be applied afterward on the real network.

% ----------------------------------
% -
% 	-- ML Architecture --
% -
% ----------------------------------
\section{Machine Learning-Aware Architecture for IEEE 802.11 WLANs}
\label{section:wlans_architecture}

IEEE 802.11 WLANs are versatile in the sense that many different kinds of deployments can be realized. Roughly, we differentiate between two main types:
\begin{itemize}
	\item \textbf{Enterprise:} a set of BSSs can be jointly operated from the edge and/or the cloud, thus providing management and orchestration functionalities (e.g., centralized authentication, channel allocation). Enterprise-like deployments are realized through extended service sets (ESS) and can be typically found in environments controlled by a single network operator, such as university campuses, offices, stadiums, etc. 
	\item \textbf{Residential:} each BSS is responsible for its own management and operation. In the context of residential scenarios (but not limited to), ad-hoc WLANs such as personal hotspots are gaining popularity for infrastructureless communications (i.e., peer-to-peer). Ad-hoc WLANs are realized through the independent basic service set (IBSS).
\end{itemize}

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\columnwidth]{overview_learning_approaches}
	\caption{Enterprise and residential-like deployments and complementary mechanisms from IEEE 802.11 amendments to enable the utilization of ML.}
	\label{fig:overview_learning_approaches}
\end{figure}

Figure \ref{fig:overview_learning_approaches} illustrates the enterprise and residential-like deployments, as well as a set of IEEE 802.11 mechanisms that can \textcolor{orange}{facilitate the adoption of the ML-based architecture in WLANs.} \textcolor{blue}{These mechanisms, which can be used for data collection, training, and output distribution, are as follows:}
\textcolor{blue}{\begin{itemize}
	\item Information gathering (802.11k/r/v): a given ML mechanism can use information about the network topology or RF measurements to infer the behavior of other devices or to extract important environmental characteristics.
	\item Interoperability (802.11f/u): interoperability with other networks can be used to perform coordinated operations (e.g., scheduling, resource allocation). Besides, inter-AP communication procedures can enable centralized/coordinated mechanisms (e.g., federated learning).
	\item Security (802.11w): ML mechanisms can use management frames that are protected so that a higher level of security is granted.
	\item Validation (802.11t): Performance evaluation in WLANs through test metrics can be of great utility to define optimization goals within the ML  operation.
\end{itemize}}

%\begin{table*}[t!]
%	\caption{Features supported by 802.11 amendments that can enable the introduction of ML methods to WLANs.}
%	\label{tab:opportunities_amendments}
%	\centering
%	\begin{tabular}{|p{.14\textwidth}|p{.1\textwidth}|p{.6\textwidth}|}
%		\hline
%		\textbf{Feature} & \textbf{Amendments} & \textbf{Opportunities for ML application} \\\hline
%		Information gathering & 802.11k/r/v & A given ML mechanism can use information about the network topology or RF measurements to infer the behavior of other devices or to extract important environmental characteristics.\\\hline
%		Interoperability & 802.11f/u & Interoperability with other networks can be used to perform coordinated operations (e.g., scheduling, resource allocation). Besides, inter-AP communication procedures can enable centralized/coordinated mechanisms (e.g., federated learning). \\\hline
%		Security & 802.11w & ML mechanisms can use management frames that are protected so that a higher level of security is granted.\\\hline
%		Validation & 802.11t & Performance evaluation in WLANs through test metrics can be of great utility to define optimization goals within the ML  operation.\\\hline
%	\end{tabular}
%\end{table*}

%%% CHALLENGES IN IEEE 802.11 WLANs
\subsection{Challenges in IEEE 802.11 WLANs}
\label{section:ieee_80211_wlans}
The application of ML methods in WLANs is tightly tied to the technological challenges posed by these types of networks. The major challenges encountered in wireless communications stand for fast data expiry and lack of resources for data handling (e.g., storage, computation, information exchange). Regarding Wi-Fi networks, we find the following challenges:
\begin{enumerate}
	\item \textbf{Network dynamics:} channel fluctuations (e.g., due to multipath fading), users mobility and varying traffic needs entail a big challenge to ML applications. As a result of network dynamics, ML methods need to constantly adapt to the environment, which may be achieved through continuous re-training.
	\item \textbf{Limited communication resources:} since Wi-Fi operates under unlicensed bands, resources are scarce and shared. Thus, any potential communication required by a certain ML mechanism (as for distributed learning) may fail or be delayed if the medium is congested. As a result, the ML operation must be robust and resilient enough to react to potential communication issues.
	\item \textbf{Limited computation and storage resources:} computation and storage resources may also be limited in WLANs, especially in residential-like deployments. Therefore, the ML operation should include computation-efficient procedures. Another implication of limited resources lies in the availability of information to be used by ML algorithms, especially for online learning methods.
	\item \textbf{Adversarial environment:} in many cases, Wi-Fi deployments are chaotic in the sense that many overlapping \textcolor{orange}{BSSs} coexist without any kind of cooperation. This is a particularly interesting challenge for ML \textcolor{orange}{methods}, which may lead to adversarial settings where different agents compete for the same resources. Moreover, multi-vendor devices may implement different ML mechanisms that may lead to clashing interests.
	\item \textbf{Legacy devices:} \textcolor{orange}{similarly} to the previous case, ML-empowered WLANs may coexist with other legacy networks that do not perform any intelligent operation. It is then required for ML methods to be aware of those legacy devices, so that \textcolor{orange}{unfair} situations are avoided.
\end{enumerate}

Apart from the aforementioned WLAN-specific challenges, other inter-domain issues should be considered. First, security is required since ML mechanisms store and/or exchange sensitive data that may be exposed. Besides, interoperability should be tackled to allow the deployment of ML solutions to different underlay networks. In this regard, the standardized ITU ML pipeline stands up as a promising solution.

%%% REALIZATION OF THE ADOPTED ARCHITECTURE
\subsection{Realization of the ML-Aware Architecture for WLANs}
The various types of WLAN deployments and their computation and communication capabilities are closely linked to the ML solutions that can be applied to them, which can be categorized into \emph{cloud} and \emph{edge-oriented}. 

Cloud-oriented ML applications are characterized by
bearing high computational and storage resources, thus allowing \textcolor{orange}{them} to collect various types of data from multiple sources and to provide global and long-term solutions. The major challenge for cloud-oriented methods lies in the management of data, which entails dealing with synchronization, availability, and heterogeneity issues.

In edge-oriented mechanisms, the ML operation is mainly ruled by edge devices (e.g., APs and/or STAs), which, contrary to the cloud approach, typically lack powerful computation and storage resources. In consequence, edge-oriented mechanisms may only allow using simple and light-weight computing ML algorithms. Nevertheless, edge servers can be placed for providing more powerful solutions \textcolor{orange}{promptly}. The edge-oriented approach is useful for real-time ML applications that manage local (and even highly-varying) information.

Besides cloud and edge-oriented settings, we may distinguish between methods based on \textcolor{orange}{their cooperation degree}. In cooperative approaches, nodes interact among them for the sake of conducting the learning operation \textcolor{orange}{jointly} (e.g., use a shared reward). With this aim, reliable and timely connections among learners are often required. In this regard, \cite{lin2017deep} showed the role of communications on speeding up a distributed training procedure over a set of nodes in a network. Alternatively, for the non-cooperative case, the learning operation may lead to adversarial settings, especially since WLANs share resources such as frequency channels.

%\begin{figure*}[ht!]
%	\centering
%	\subfigure[ML approaches]{\includegraphics[width=1\columnwidth]{ml_architecture_wlan_1}\label{fig:ml_architecture_wlan_1}}
%	\subfigure[Realization of the ML pipeline]{\includegraphics[width=1\columnwidth]{ml_architecture_wlan_2}\label{fig:ml_architecture_wlan_2}}
%	\caption{Realization of the ITU's ML architecture in IEEE 802.11 WLANs. (a) ML approaches based on the communication level and participating elements, (b) ML pipeline realization of a hybrid ML-based solution for AP (re)association and handover.}
%	\label{fig:ml_architecture_wlan}
%\end{figure*}

\subsubsection{Example of the adoption of the architecture}
By adopting the ITU's architecture, multiple entities in the ML pipeline can be activated at different locations of the network, according to the selected learning approach. This expands the concept of cloud and edge computing and leads to hybrid solutions.% (e.g., combining centralized channel allocation with decentralized spatial reuse). 

To illustrate this (see Fig. \ref{fig:ml_architecture_wlan}), let us retake the AP (re)association and handover example. We now consider a hybrid solution whereby two main ML-oriented processes are held: training (learn from data) and placement (apply the learned knowledge). While the training procedure is carried out at the cloud (collect data from multiple sources), the placement operation is done at the edge (provide timely responses to new cases). Notice that the placement phase can also contribute to re-train the system in an online manner. % shows the elements in the ML pipeline that participate in the aforementioned example. 

\begin{figure}[ht!]
	\includegraphics[width=1\columnwidth]{ml_architecture_wlan_2}
	\caption{Realization of the ITU's ML architecture for IEEE 802.11 WLANs through a hybrid ML-based solution for AP (re)association and handover.}
	\label{fig:ml_architecture_wlan}
\end{figure}

Specifically, the training procedure consists of the following steps (shown \textcolor{orange}{in} red):
\begin{enumerate}
	\item \textbf{Data collection:} the edge server collects information of different \textcolor{orange}{kind} from either APs and STAs, such as user information (e.g., current location), performance (e.g., throughput, delay), application data (e.g., traffic load), or channel status reports (e.g., the power received from interfering nodes). This information can be used either for training or feeding auxiliary algorithms that help the main AP association procedure (e.g., predict user behavior).
	\item \textbf{ML input preparation:} the data collected at the cloud is prepared by the pre-processor so that the ML method can properly manage it. For instance, in case of applying a multiple linear regression, the input user information needs to be converted into normalized features (e.g., convert the throughput given in Mbps into a scalar between 0 and 1).
	\item \textbf{ML method application:} \textcolor{orange}{the final output of the ML takes policies into account. Accordingly,} a given AP may \textcolor{orange}{consider} specific constraints regarding its occupation or the maximum number of associated STAs. The policies are strongly tied to the capabilities of the devices or the existing regulations (e.g., frequency channels available, maximum regulated transmission power).
	\item \textbf{Output distribution:} once the ML method generates the output (i.e., the predicted function for new (re)associations), it is distributed throughout the sink edge servers, which are then prepared to give quick response to new cases.
\end{enumerate}

When it comes to placement phase, we find the following operations (shown \textcolor{orange}{in} green):
\begin{enumerate}
	\item \textbf{Handle new cases:} new (re)association requests or potential handovers are detected based on newly acquired information from STAs. This information is collected by the edge server.
	\item \textbf{Pre-processing:} the acquired information is then processed by the edge server, as for the training phase.
	\item \textbf{Run the ML solution:} the ML method provided by the cloud is applied locally at the edge server, which provides an output for the new placement case.
	\item \textbf{Apply the ML solution:} finally, the output solution to new (re)association cases is distributed to the corresponding sinks.
\end{enumerate}

Finally, it is worth pointing out the role of the sandbox (e.g., a simulated environment), which can be mainly twofold (shown \textcolor{orange}{in} orange):
\begin{enumerate}
	\item \textbf{Generate data for training:} the sandbox can act as a source in the ML pipeline by generating synthetic data for training purposes. Nevertheless, the data provided by the sandbox is limited to several factors such as the accuracy of the simulation model or the degree of similarity between the sandbox and the real network. %Also, data collected from the network can be used in the sandbox.
	\item \textbf{Preliminary model testing:} alternatively, the sandbox can be used to validate the output of the ML method before being applied to the real network.
\end{enumerate}

\textcolor{blue}{To showcase the potential of the ML-based architecture through numerical results,\footnote{\textcolor{blue}{Given the novelty of the technologies studied in this paper, our results have been obtained from well-know models, hence their accuracy is tied to them. Nevertheless, this is a first step to understand the potential benefits of using an ML-based architecture in next-generation wireless networks. For the sake of reproducibility and disclosure, all the source code is open and publicly available at \url{https://github.com/fwilhelmi/machine_learning_aware_architecture_wlans}, accessed on 20 January 2020.}} Fig. \ref{fig:results_use_case} compares the performance of classical AP association procedure (strongest signal first (SSF)) with a novel ML-based approach (based on vanilla neural networks). As illustrated, the ML approach allows capturing complex patterns from dense deployments, which is useful to improve satisfaction ratio and fairness in the AP (re)association problem.}

\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.9\columnwidth]{results_use_case}
	\caption{\textcolor{blue}{Results of applying the hybrid ML-based AP (re)association and handover in IEEE 802.11 WLANs. Different number of STAs are considered to showcase the impact of load on APs. For each mechanism, the average performance is represented by a star.}}
	\label{fig:results_use_case}
\end{figure}

\section{Concluding Remarks}
In order to sustain progress in wireless networks, it is needed to accommodate the operation of ML as an intrinsic part of communications. Nevertheless, current networks are not yet prepared for the pervasive adoption of ML-based operation. Hence, disruptive architectural changes are required. For the sake of moving forward in this field, this article introduced the ITU's unified architecture for future networks and provided a realization for IEEE 802.11 WLANs. The different forms of Wi-Fi networks allow uplifting the flexibility characteristic of the ITU's architecture, thus empowering from edge to cloud-oriented approaches, including hybrid approaches.

To conclude, future wireless networks are envisioned to share a common flexible architecture that allows a fast adaptation of resources to accommodate a plethora of ML-enabled network verticals. Nevertheless, a lot of effort is still required before reaching fully intelligent wireless networks. Among several open issues, we highlight the ones related to data handling (\textit{how and where to store data? how to assess the expiry of data?}), orchestration (\textit{how would several ML approaches would behave in conjunction? how to distribute the ML operation? how to deal with heterogeneity?}), and robustness of the ML methods (\textit{how to deal with uncertainty? how to prevent network failures?}). 

% use section* for acknowledgment
\section*{Acknowledgment}

This work has been partially supported by grants MDM-2015-0502, 2017-SGR-11888, by WINDMAL PGC2018-099959-B-I00 (MCIU/AEI/FEDER,UE), by a Gift from the Cisco University Research Program (CG\#890107) Fund, and by SPOTS project (RTI2018-095438-A-I00) funded by the Spanish Ministry of Science, Innovation and Universities. The work by Sergio Barrachina-Mu\~noz is supported by an FI grant from Generalitat de Catalunya.


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
\bibliography{bibliography}

% if you will not have a photo at all:
\begin{IEEEbiographynophoto}{Francesc Wilhelmi}
(francisco.wilhelmi@upf.edu) holds a B.Sc. degree in Telematics Engineering (2015) and an M.Sc. in Intelligent and Interactive Systems (2016), both from Universitat Pompeu Fabra (UPF). He is currently pursuing a Ph.D. in Information and Communication Technologies at UPF.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Sergio Barrachina-Mu\~noz}
(sergio.barrachina@upf.edu) obtained his B.Sc. degree in Telematics Engineering and his M.Sc. in Intelligent Interactive Systems in 2015 and 2016, respectively, both from Universitat Pompeu Fabra (UPF), Barcelona. Currently, he is a PhD student and teacher assistant in the Wireless Networking research group at UPF.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Boris Bellalta}
(boris.bellalta@upf.edu) is an Associate Professor in the Department of Information and Communication Technologies (DTIC) at Universitat Pompeu Fabra (UPF). He is the head of the Wireless Networking research group at DTIC/UPF.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Cristina Cano}
	(ccanobs@uoc.edu) holds a Ph.D. (2011) in Information, Communication and Audiovisual Media Technologies from Universitat Pompeu Fabra (UPF). She has been a research fellow in the Hamilton Institute of the National University of Ireland, Maynooth (2012-2014), in Trinity College Dublin (2015-2016) and in Inria-Lille in France (first half of 2016). Currently, she is an associate professor at Universitat Oberta de Catalunya (UOC). 
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Anders Jonsson}
(anders.jonsson@upf.edu) is the director of the Artificial Intelligence and Machine Learning group at Universitat Pompeu Fabra (UPF). He received his Ph.D. in computer science in 2005 from the University of Massachusetts Amherst, USA, and has been at UPF ever since.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Vishnu Ram}
(vishnu.n@ieee.org) worked for Motorola/Nokia/Siemens in advanced technologies teams for 21 years. He was a Scientific Advisory Board Associate (SABA) member of Motorola Networks. He has published several drafts in IETF, contributed to ETSI, 3GPP in his role as a senior specialist (Radio Resource Management). He is currently working as an Independent Researcher.	
\end{IEEEbiographynophoto}

\vfill

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


